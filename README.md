# ðŸ›°ï¸ RepoRover

**Chat with any public GitHub repository using AI.**  
No database. No setup. Just bring your Groq API key.

## How it works

1. Paste a public GitHub repo URL
2. RepoRover clones it, parses all Python files with Tree-sitter
3. Builds an in-memory code graph using NetworkX
4. You chat â€” questions are answered by Groq (Llama 3.3) using the graph as context

## Quick Start

```bash
pip install -r requirements.txt
streamlit run app.py
```


## Tech Stack

- **Streamlit** â€” UI
- **Tree-sitter** â€” Python code parsing
- **NetworkX** â€” In-memory code graph 
- **LangChain + Groq** â€” LLM question answering (Llama 3.3 70B)

## Architecture

```
User pastes GitHub URL
        â†“
git clone --depth=1 (tmpdir)
        â†“
Tree-sitter parses all .py files
        â†“
NetworkX graph: File --[DEFINES]--> CodeEntity
        â†“
User asks a question
        â†“
Smart context extraction from graph
        â†“
Groq LLM answers with graph context
        â†“
tmpdir deleted after clone
```

## Limitations

- Public repos only
- Python files only (for now)
- Large repos (1000+ files) may be slow on free hosting
- Graph lives in memory â€” cleared on session end
