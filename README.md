# ðŸ›°ï¸ RepoRover

**Chat with any public GitHub repository using AI.**  
No database. No setup. Just bring your Groq API key.

## How it works

1. Paste a public GitHub repo URL
2. RepoRover clones it and parses **all files** (Python, JavaScript, config files, Markdown, and more)
3. Builds an in-memory code graph using NetworkX (Python files get function/class extraction via Tree-sitter)
4. You chat â€” questions are answered by Groq (Llama 3.3) using the graph as context

## Quick Start

```bash
pip install -r requirements.txt
streamlit run app.py
```

## Tech Stack

- **Streamlit** â€” UI
- **Tree-sitter** â€” Python code parsing (functions & classes)
- **NetworkX** â€” In-memory code graph
- **LangChain + Groq** â€” LLM question answering (Llama 3.3 70B)

## Architecture

```
User pastes GitHub URL
        â†“
git clone --depth=1 (tmpdir)
        â†“
Scan all files (exclude binaries: images, archives, etc.)
        â†“
Python files â†’ Tree-sitter parses functions & classes
Other files â†’ Raw content stored as single entity
        â†“
NetworkX graph: File --[DEFINES]--> CodeEntity
        â†“
User asks a question
        â†“
Smart context extraction from graph
        â†“
Groq LLM answers with graph context
        â†“
tmpdir deleted after clone
```

## Supported Files

- **Python (`.py`)** â€” Full parsing of functions and classes
- **All other text files** â€” JavaScript, TypeScript, JSON, YAML, MD, HTML, CSS, configs, etc. (stored as raw content)
- Binary files (images, archives, fonts) are automatically skipped

## Limitations

- Public repos only
- Large repos may be slow on free hosting
- Graph lives in memory â€” cleared on session end
